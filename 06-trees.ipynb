{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83f3840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0240a7",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "In this homework, we will use the California Housing Prices from [Kaggle](https://www.kaggle.com/datasets/camnugent/california-housing-prices).\n",
    "\n",
    "Here's a wget-able [link](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv):\n",
    "\n",
    "```bash\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\n",
    "```\n",
    "\n",
    "The goal of this homework is to create a regression model for predicting housing prices (column `'median_house_value'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75cb7fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fdb5272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ba67e5",
   "metadata": {},
   "source": [
    "### Preparing the dataset \n",
    "\n",
    "For this homework, we only want to use a subset of data. This is the same subset we used in homework #2.\n",
    "But in contrast to homework #2 we are going to use all columns of the dataset.\n",
    "\n",
    "First, keep only the records where `ocean_proximity` is either `'<1H OCEAN'` or `'INLAND'`\n",
    "\n",
    "Preparation:\n",
    "\n",
    "* Fill missing values with zeros.\n",
    "* Apply the log tranform to `median_house_value`.\n",
    "* Do train/validation/test split with 60%/20%/20% distribution. \n",
    "* Use the `train_test_split` function and set the `random_state` parameter to 1.\n",
    "* Use `DictVectorizer(sparse=True)` to turn the dataframes into matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c4883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.loc[data.ocean_proximity.isin(['<1H OCEAN', 'INLAND'])].reset_index(drop=True)\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df['median_house_value'] = np.log1p(df.median_house_value.to_numpy())\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.median_house_value.values\n",
    "y_val = df_val.median_house_value.values\n",
    "y_test = df_test.median_house_value.values\n",
    "\n",
    "df_train.drop(['median_house_value'], axis=1, inplace=True)\n",
    "df_val.drop(['median_house_value'], axis=1, inplace=True)\n",
    "df_test.drop(['median_house_value'], axis=1, inplace=True)\n",
    "\n",
    "dv = DictVectorizer(sparse=True)\n",
    "\n",
    "train_dict = df_train.to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "val_dict = df_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a91e3",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the `median_house_value` variable. \n",
    "\n",
    "* Train a model with `max_depth=1`.\n",
    "\n",
    "\n",
    "Which feature is used for splitting the data?\n",
    "\n",
    "* `ocean_proximity`\n",
    "* `total_rooms`\n",
    "* `latitude`\n",
    "* `population`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50f9e38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- ocean_proximity=<1H OCEAN <= 0.50\n",
      "|   |--- value: [11.61]\n",
      "|--- ocean_proximity=<1H OCEAN >  0.50\n",
      "|   |--- value: [12.30]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=1)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "print(export_text(dt, feature_names=dv.feature_names_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e57e2cb",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Train a random forest model with these parameters:\n",
    "\n",
    "* `n_estimators=10`\n",
    "* `random_state=1`\n",
    "* `n_jobs=-1` (optional - to make training faster)\n",
    "\n",
    "\n",
    "What's the RMSE of this model on validation?\n",
    "\n",
    "* 0.045\n",
    "* 0.245\n",
    "* 0.545\n",
    "* 0.845"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62fc2e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE of this model on the validation set is 0.245\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_val)\n",
    "print(f\"The RMSE of this model on the validation set is {round(np.sqrt(mean_squared_error(y_val, y_pred)), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c03a247",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Now let's experiment with the `n_estimators` parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10.\n",
    "* Set `random_state` to `1`.\n",
    "* Evaluate the model on the validation dataset.\n",
    "\n",
    "\n",
    "After which value of `n_estimators` does RMSE stop improving?\n",
    "\n",
    "- 10\n",
    "- 25\n",
    "- 50\n",
    "- 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83744863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE stops improving after 50 trees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11185/553662491.py:16: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  best_n_estimators = int(df_scores.loc[df_scores.rmse_diff>=0, 'n_estimators'].head(1).values)\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for n in np.arange(10, 200, 10, dtype=int):\n",
    "    rf = RandomForestRegressor(n_estimators=n, random_state=1, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = rf.predict(X_val)\n",
    "    score = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    \n",
    "    scores.append([n, round(score, 3)])\n",
    "\n",
    "df_scores = pd.DataFrame(scores, columns=['n_estimators', 'rmse'])\n",
    "\n",
    "df_scores[\"rmse_diff\"] = df_scores[\"rmse\"].diff()\n",
    "\n",
    "best_n_estimators = int(df_scores.loc[df_scores.rmse_diff>=0, 'n_estimators'].head(1).values)\n",
    "\n",
    "print(f\"RMSE stops improving after {best_n_estimators} trees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a81b6f6",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Let's select the best `max_depth`:\n",
    "\n",
    "* Try different values of `max_depth`: `[10, 15, 20, 25]`\n",
    "* For each of these values, try different values of `n_estimators` from 10 till 200 (with step 10)\n",
    "* Fix the random seed: `random_state=1`\n",
    "\n",
    "\n",
    "What's the best `max_depth`:\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d32a10b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth considering RMSE min is 25\n",
      "Best max_depth considering RMSE mean is 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11185/4119146460.py:20: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  min_score_max_depth = int(df_scores.groupby(\"max_depth\", as_index=False)[\"rmse\"] \\\n",
      "/tmp/ipykernel_11185/4119146460.py:26: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  mean_score_max_depth = int(df_scores.groupby(\"max_depth\", as_index=False)[\"rmse\"] \\\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for d in [10, 15, 20, 25]:\n",
    "    \n",
    "    for n in np.arange(10, 200, 10, dtype=int):\n",
    "        rf = RandomForestRegressor(n_estimators=n,\n",
    "                                   max_depth=d,\n",
    "                                   random_state=1, \n",
    "                                   n_jobs=-1,\n",
    "                                   warm_start=True)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = rf.predict(X_val)\n",
    "        score = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "        scores.append((d, n, score))\n",
    "\n",
    "df_scores = pd.DataFrame(scores, columns=['max_depth', 'n_estimators', 'rmse'])\n",
    "\n",
    "min_score_max_depth = int(df_scores.groupby(\"max_depth\", as_index=False)[\"rmse\"] \\\n",
    "                                      .min() \\\n",
    "                                      .sort_values(by=['rmse'])['max_depth'] \\\n",
    "                                      .head(1) \\\n",
    "                                      .values)\n",
    "\n",
    "mean_score_max_depth = int(df_scores.groupby(\"max_depth\", as_index=False)[\"rmse\"] \\\n",
    "                                      .mean() \\\n",
    "                                      .sort_values(by=['rmse'])['max_depth'] \\\n",
    "                                      .head(1) \\\n",
    "                                      .values)\n",
    "\n",
    "print(f\"Best max_depth considering RMSE min is {min_score_max_depth}\")\n",
    "print(f\"Best max_depth considering RMSE mean is {mean_score_max_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d4a099",
   "metadata": {},
   "source": [
    "\n",
    "## Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models. \n",
    "\n",
    "At each step of the decision tree learning algorith, it finds the best split. \n",
    "When doint it, we can calculate \"gain\" - the reduction in impurity before and after the split. \n",
    "This gain is quite useful in understanding what are the imporatant features \n",
    "for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the\n",
    "[`feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.feature_importances_)\n",
    "field. \n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "* Train the model with these parametes:\n",
    "    * `n_estimators=10`,\n",
    "    * `max_depth=20`,\n",
    "    * `random_state=1`,\n",
    "    * `n_jobs=-1` (optional)\n",
    "* Get the feature importance information from this model\n",
    "\n",
    "\n",
    "What's the most important feature (among these 4)? \n",
    "\n",
    "* `total_rooms`\n",
    "* `median_income`\n",
    "* `total_bedrooms`\n",
    "* `longitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dbf795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most important feature is median_income\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=10, \n",
    "                           max_depth=20, \n",
    "                           random_state=1, \n",
    "                           n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "df_importances = pd.DataFrame()\n",
    "df_importances['feature'] = dv.feature_names_\n",
    "df_importances['importance'] = rf.feature_importances_\n",
    "\n",
    "most_important_feature = df_importances.sort_values(by='importance', ascending=False)['feature'].head(1).values[0]\n",
    "\n",
    "print(f\"The most important feature is {most_important_feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553c4fd",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "Now let's train an XGBoost model! For this question, we'll tune the `eta` parameter:\n",
    "\n",
    "* Install XGBoost\n",
    "* Create DMatrix for train and validation\n",
    "* Create a watchlist\n",
    "* Train a model with these parameters for 100 rounds:\n",
    "\n",
    "```\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "```\n",
    "\n",
    "Now change `eta` from `0.3` to `0.1`.\n",
    "\n",
    "Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n",
    "* 0.3\n",
    "* 0.1\n",
    "* Both give equal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "174f755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dv.feature_names_\n",
    "\n",
    "features = [col.replace(\"<\", \"lt\") for col in features]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=features)\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5eb85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = {}\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100,\n",
    "                  evals=watchlist, verbose_eval=False, evals_result=progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5acbd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['eta=0.3'] = pd.DataFrame(data={'num_iter': range(0, len(progress['train']['rmse'])),\n",
    "                                       'train_rmse': progress['train']['rmse'],\n",
    "                                       'val_rmse': progress['val']['rmse']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da565405",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = {}\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.1, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100,\n",
    "                  evals=watchlist, verbose_eval=False, evals_result=progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23d606e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores['eta=0.1'] = pd.DataFrame(data={'num_iter': range(0, len(progress['train']['rmse'])),\n",
    "                                       'train_rmse': progress['train']['rmse'],\n",
    "                                       'val_rmse': progress['val']['rmse']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27c61ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta=0.3 leads to the best RMSE score on the validation dataset\n"
     ]
    }
   ],
   "source": [
    "if scores['eta=0.3'].val_rmse.min() < scores['eta=0.1'].val_rmse.min():\n",
    "    print(\"eta=0.3 leads to the best RMSE score on the validation dataset\")\n",
    "elif scores['eta=0.3'].val_rmse.min() > scores['eta=0.1'].val_rmse.min():\n",
    "    print(\"eta=0.1 leads to the best RMSE score on the validation dataset\")\n",
    "else:\n",
    "    print(\"Both give equal value\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-zoomcamp] *",
   "language": "python",
   "name": "conda-env-ml-zoomcamp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
